{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":636393,"sourceType":"datasetVersion","datasetId":312121}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Установка необходимых библиотек и зависимостей","metadata":{}},{"cell_type":"code","source":"#!pip install torchdiffeq\n#!pip install torchviz\n#!pip install pmdarima\n\nfrom torchdiffeq import odeint_adjoint as odeadj\nimport numpy as np\nimport pandas as pd\nimport torch\nimport warnings\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom sklearn.metrics import mean_absolute_error\nimport time\nfrom pympler import asizeof\nfrom torchviz import make_dot\nimport pmdarima as pm\n\n#warnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Функции для измерения числа параметров и используемой памяти для нейросетевых моделей","metadata":{}},{"cell_type":"code","source":"def memory_usage(model):\n  mem_params = sum([param.nelement()*param.element_size() for param in model.parameters()])\n  mem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\n  mem = mem_params + mem_bufs\n  return mem","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_summary(model):\n  print(\"model_summary\")\n  print()\n  print(\"Layer_name\"+\"\\t\"*7+\"Number of Parameters\")\n  print(\"=\"*100)\n  model_parameters = [layer for layer in model.parameters() if layer.requires_grad]\n  layer_name = [child for child in model.children()]\n  j = 0\n  total_params = 0\n  print(\"\\t\"*10)\n  for i in layer_name:\n    print()\n    param = 0\n    try:\n      bias = (i.bias is not None)\n    except:\n      bias = False  \n    if not bias:\n      param =model_parameters[j].numel()+model_parameters[j+1].numel()\n      j = j+2\n    else:\n      param =model_parameters[j].numel()\n      j = j+1\n    print(str(i)+\"\\t\"*3+str(param))\n    total_params+=param\n  print(\"=\"*100)\n  print(f\"Total Params:{total_params}\")\n  return total_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Подготовка данных","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/daily-climate-time-series-data/DailyDelhiClimateTrain.csv\", parse_dates=['date'])\ntest = pd.read_csv(\"/kaggle/input/daily-climate-time-series-data/DailyDelhiClimateTest.csv\", parse_dates=['date'])\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.iloc[:-1, :]\ntrain.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_box_fts(train):\n    fig = make_subplots(rows=2, cols=2)\n    fig.add_trace(\n        go.Box(y=train[\"humidity\"], name=\"Влажность\"),\n        row=1, col=1\n    )\n    fig.add_trace(\n        go.Box(y=train[\"wind_speed\"], name=\"Скорость ветра\"),\n        row=1, col=2\n    )\n    fig.add_trace(\n        go.Box(y=train[\"meanpressure\"], name=\"Среднее давление\"),\n        row=2, col=1\n    )\n    fig.add_trace(\n        go.Box(y=train[\"meantemp\"], name=\"Средняя температура\"),\n        row=2, col=2\n    )\n    fig.update_layout(showlegend=False)\n    fig.show()\n\nplot_box_fts(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Функции для избавления от выбросов в данных","metadata":{}},{"cell_type":"code","source":"def get_outlier_iqr_limits(data, column, qr1=0.25, qr3=0.75):\n    quartile1 = data[column].quantile(qr1)\n    quartile3 = data[column].quantile(qr3)\n    iqr = quartile3 - quartile1\n    low, up = quartile1 - 1.5 * iqr, quartile3 + 1.5 * iqr\n    return low, up\ndef replace_outliers(data, columns):\n    for column in columns:\n        low, up = get_outlier_iqr_limits(data, column)\n        data[column] = np.where(data[column] < low, low, \n            np.where(data[column] > up, up, data[column])\n        )\n    return data\n\ntrain = replace_outliers(train, [\"humidity\", \"wind_speed\", \"meanpressure\", \"meantemp\"])\n#test = replace_outliers(test, [\"humidity\", \"wind_speed\", \"meanpressure\", \"meantemp\"])\n\nplot_box_fts(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.set_index(\"date\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Разделение выборок на тренировочную и тестовую, применение StandardScaler","metadata":{}},{"cell_type":"code","source":"df = pd.concat([train, test.set_index(\"date\")])\nfts = {}\nforecast_lead = 1\ndf_tmp = df.copy()\nleadings = []\ndfs = []\nfor tgt_col in [\"humidity\", \"wind_speed\", \"meanpressure\", \"meantemp\"]:\n    df_in = df_tmp.copy()\n    fts.update({tgt_col: list(df_tmp.columns.difference([tgt_col]))})\n    tgt = f\"{tgt_col}{forecast_lead}\"\n    leadings.append(tgt)\n    df_in[tgt] = df_in[tgt_col].shift(-forecast_lead)\n    dfs.append(df_in.iloc[:-forecast_lead])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_start = \"2016-01-01\"\n\ndf_data = []\n\nfor df in dfs:\n    df_train = df.loc[:test_start].iloc[:-1].copy()\n    df_test = df.loc[test_start:].copy()\n    df_data.append([df_train, df_test])\n    \n    print(f\"Train size: {len(df_train)}\")\n    print(f\"Test size: {len(df_test)}\")\n    \n    print(f\"Test fraction: {len(df_test) / len(df)}\")\n    \n    scaler = StandardScaler()\n    \n    df_data[-1].append(scaler)\n    \n    init_columns = df.columns\n    \n    df_data[-1][0] = pd.DataFrame(scaler.fit_transform(df_train), columns=init_columns)\n    df_data[-1][1] = pd.DataFrame(scaler.transform(df_test), columns=init_columns)\n    \n    print(df_train.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Подготовка и тестирование SARIMA","metadata":{}},{"cell_type":"code","source":"'''\n!pip install pmdarima\nimport pmdarima as pm\n\nsarimax_temp = pm.auto_arima(df_train[\"meantemp\"], start_p=1, start_q=1,test='adf',\n                         max_p=3, max_q=3, m=365,\n                         start_P=0, seasonal=True,\n                         d=None, D=1, trace=True,\n                         error_action='ignore',  \n                         suppress_warnings=True, \n                         stepwise=True)'''\n\nend_time = 0\n\nstart_time = time.time()\nsarimax_temp = ARIMA(df_train[\"meantemp\"], order=(1, 1, 1), seasonal_order=(1, 1, 0, 365))\nsarimax_res_temp = sarimax_temp.fit(method='innovations_mle', low_memory=True, cov_type='none')\nend_time += time.time() - start_time\nprint(\"SARIMA тренировка temp: \", end_time)\nend_time = 0\n\nstart_time = time.time()\nsarimax_hum = ARIMA(df_train[\"humidity\"], order=(1, 1, 1), seasonal_order=(1, 1, 0, 365))\nsarimax_res_hum = sarimax_hum.fit(method='innovations_mle', low_memory=True, cov_type='none')\nend_time += time.time() - start_time\nprint(\"SARIMA тренировка hum: \", end_time)\nend_time = 0\n\nstart_time = time.time()\nsarimax_pres = ARIMA(df_train[\"meanpressure\"], order=(1, 1, 1), seasonal_order=(1, 1, 0, 365))\nsarimax_res_pres = sarimax_pres.fit(method='innovations_mle', low_memory=True, cov_type='none')\nend_time += time.time() - start_time\nprint(\"SARIMA тренировка pres: \", end_time)\nend_time = 0\n\nstart_time = time.time()\nsarimax_wind = ARIMA(df_train[\"wind_speed\"], order=(1, 1, 1), seasonal_order=(1, 1, 0, 365))\nsarimax_res_wind = sarimax_wind.fit(method='innovations_mle', low_memory=True, cov_type='none')\nend_time += time.time() - start_time\nprint(\"SARIMA тренировка wind: \", end_time)\nend_time = 0\n\nstart_time = time.time()\nsarimax_pred_temp = sarimax_res_temp.predict(start=df_test.index.min(), end=df_test.index.max(), dynamic=True)\nend_time += time.time() - start_time\nprint(\"SARIMA тест wind: \", end_time)\nend_time = 0\nstart_time = time.time()\nsarimax_pred_hum = sarimax_res_hum.predict(start=df_test.index.min(), end=df_test.index.max(), dynamic=True)\nend_time += time.time() - start_time\nprint(\"SARIMA тест wind: \", end_time)\nend_time = 0\nstart_time = time.time()\nsarimax_pred_pres = sarimax_res_pres.predict(start=df_test.index.min(), end=df_test.index.max(), dynamic=True)\nend_time += time.time() - start_time\nprint(\"SARIMA тест wind: \", end_time)\nend_time = 0\nstart_time = time.time()\nsarimax_pred_wind = sarimax_res_wind.predict(start=df_test.index.min(), end=df_test.index.max(), dynamic=True)\nend_time += time.time() - start_time\nprint(\"SARIMA тест wind: \", end_time)\nend_time = 0\n\ntemp_concated = pd.concat([sarimax_res_temp.fittedvalues, sarimax_pred_temp])\nhum_concated = pd.concat([sarimax_res_hum.fittedvalues, sarimax_pred_hum])\npres_concated = pd.concat([sarimax_res_pres.fittedvalues, sarimax_pred_pres])\nwind_concated = pd.concat([sarimax_res_wind.fittedvalues, sarimax_pred_wind])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Класс для кастомной работы с датасетом","metadata":{}},{"cell_type":"code","source":"class SDS(Dataset):\n    def __init__(self, df, tgt, fts, lngt=7):\n        self.fts = fts\n        self.tgt = tgt\n        self.lngt = lngt\n        self.x = torch.tensor(df[fts].values).float()\n        self.y = torch.tensor(df[tgt].values).float()\n        \n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, idx):\n        if idx >= self.lngt - 1:\n            idx_start = idx - self.lngt + 1\n            x = self.x[idx_start:(idx + 1), :]\n        else:\n            padding = self.x[0].repeat(self.lngt - idx - 1, 1)\n            x = self.x[0:(idx + 1), :]\n            x = torch.cat((padding, x), 0)\n\n        return x, self.y[idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Класс LSTM","metadata":{}},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, fts_cnt, hidden_sz):\n        super().__init__()\n        self.fts_cnt = fts_cnt\n        self.hidden_sz = hidden_sz\n        self.num_layers = 1\n        \n        self.lstm = nn.LSTM(\n            input_size=fts_cnt,\n            hidden_size=hidden_sz,\n            num_layers=self.num_layers,\n            batch_first=True,\n        )\n        \n        self.linear = nn.Linear(in_features=self.hidden_sz, out_features=1)\n    \n    def forward(self, x):\n        b_size = x.shape[0]\n        h0 = torch.zeros(self.num_layers, b_size, self.hidden_sz).requires_grad_()\n        c0 = torch.zeros(self.num_layers, b_size, self.hidden_sz).requires_grad_()\n        \n        output, (h_n, c_n) = self.lstm(x, (h0, c0))\n        res = self.linear(h_n[0]).squeeze()\n        return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Классы для работы с ODENet","metadata":{}},{"cell_type":"code","source":"class f(nn.Module):\n    def __init__(self, dim):\n        super(f, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.ReLU(),\n            nn.Linear(dim, dim),\n            nn.Tanh()\n        )\n\n    def forward(self, t, x):\n        return self.model(x)\n\nclass ODEBlock(nn.Module):\n    def __init__(self, f):\n        super(ODEBlock, self).__init__()\n        self.f = f\n        self.integration_time = torch.Tensor([0, 1]).float()\n\n    def forward(self, x):\n        self.integration_time = self.integration_time.type_as(x)\n        tol = 0.25 #0.25\n        out = odeadj(self.f, x, self.integration_time, rtol = tol, atol = tol)\n        return out[1]\n\nclass ODENet(nn.Module):\n    def __init__(self, fts_cnt, hidden_sz):\n        super(ODENet, self).__init__()\n        self.fc1 = nn.Linear(fts_cnt, hidden_sz)\n        self.relu1 = nn.ReLU()\n        self.ode_block = ODEBlock(f(dim=hidden_sz))\n        self.fc2 = nn.Linear(hidden_sz, 1)\n\n    def forward(self, x):\n        batch_size = x.shape[0]\n        x = x.view(batch_size, -1)\n\n        out = self.fc1(x)\n        out = self.relu1(out)\n        out = self.ode_block(out)\n        out = self.fc2(out).squeeze()\n        \n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Функция для получения предсказаний в нейросетевых моделях","metadata":{}},{"cell_type":"code","source":"def make_predictions(loader, model):\n    outputs = torch.tensor([])\n    model.eval()\n    with torch.inference_mode():\n        for x, y in loader:\n            pred = model(x)\n            outputs = torch.cat((outputs, pred), 0)\n    return outputs.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Тренировка и тестирование для нейросетевых моделей","metadata":{}},{"cell_type":"code","source":"#torch.manual_seed(42)\n#\"humidity\", \"wind_speed\", \"meanpressure\", \"meantemp\"\nbatch_size = 113#5\nlngt = 14\n\nhidden_size = 16\nlr = 1e-3 #1e-3\n\n\nepochs = 50 #7\n\npredictions = {}\n\nLSTMn = LSTM(3, 32)\nNeuralODE = ODENet(42, 32)\n\nmodels = [{\"name\": \"LSTM\", \"model\": LSTMn, \"params\": [], \"memory\": [], \"other_memory\": [], \"hwpt_train\": [], \"hwpt_test\": []},\n         {\"name\": \"ODENET\", \"model\": NeuralODE, \"params\": [], \"memory\": [], \"other_memory\": [], \"hwpt_train\": [], \"hwpt_test\": []}]\n\nfor mdl in models:\n    flag = True\n    \n    predictions[mdl[\"name\"]] = {}\n    for idx, lead in enumerate(leadings):\n        train_dataset = SDS(\n            df_data[idx][0],\n            tgt=lead,\n            fts=fts[lead[:-1]],\n            lngt=lngt\n        )\n        test_dataset = SDS(\n            df_data[idx][1],\n            tgt=lead,\n            fts=fts[lead[:-1]],\n            lngt=lngt\n        )\n        \n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n        x, y = next(iter(train_loader))\n        model = mdl[\"model\"]\n        loss_fn = nn.MSELoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n        \n        test_loss_global = []\n        \n        end_time_train = 0\n        \n        for epoch in range(epochs):\n            \n            start_time_train = time.time()\n            \n            train_loss = []\n            model.train()\n            for x, y in train_loader:\n                out = model(x)\n                if flag:\n                    make_dot(out, params=dict(model.named_parameters())).render(\"test_\" + mdl[\"name\"], format=\"png\")\n                    flag = False\n                loss = loss_fn(out, y)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                train_loss.append(loss.item())\n                \n            end_time_train += time.time() - start_time_train\n            \n            test_loss = []\n            model.eval()\n            with torch.inference_mode():\n                for x, y in test_loader:\n                    out = model(x)\n                    loss = loss_fn(out, y)\n                    test_loss.append(loss.item())\n                    \n            mean_loss_test = np.mean(test_loss)\n\n        params = model_summary(model)\n        memory = memory_usage(model)\n\n        df_train_final = pd.DataFrame(df_data[idx][2].inverse_transform(df_data[idx][0]), columns=df_data[idx][0].columns)\n        df_test_final = pd.DataFrame(df_data[idx][2].inverse_transform(df_data[idx][1]), columns=df_data[idx][1].columns)\n        train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n        pred_column = \"prediction\"\n        \n        start_time_test = time.time()\n        \n        df_train_final[pred_column] = make_predictions(train_eval_loader, model)\n        df_test_final[pred_column] = make_predictions(test_loader, model)\n        \n        end_time_test = time.time() - start_time_test\n        \n        df_all_concat = pd.concat([df_train_final, df_test_final])\n        df_all_concat[pred_column] = df_all_concat[pred_column] * df_data[idx][2].scale_[-1] + df_data[idx][2].mean_[-1]\n        df_all_concat = df_all_concat.set_index(df.index)\n        predictions[mdl[\"name\"]].update({lead[:-1]: df_all_concat})\n        \n        mdl[\"params\"].append(params)\n        mdl[\"memory\"].append(memory)\n        mdl[\"hwpt_train\"].append(end_time_train)\n        mdl[\"hwpt_test\"].append(end_time_test)\n        mdl[\"other_memory\"].append(asizeof.asizeof(model))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Добавление начальных точек в SARIMA для корректного отображения графиков","metadata":{}},{"cell_type":"code","source":"pres_concated['2014-01-1'] = 1016.522324 # заменяем на среднее для корректного отображения графика для SARIMA на тренировочной выборке\npres_concated['2013-01-1'] = 1014.678912\nhum_concated['2013-01-1'] = 80.522324\ntemp_concated['2013-01-1'] = 12.348657\nwind_concated['2013-01-1'] = 5.947657","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Установка набора цветов для графиков","metadata":{}},{"cell_type":"code","source":"colors = [[\"#87cefa\",\"#3cb371\",\"#ffd700\"],[\"#00bfff\",\"#228b22\",\"#ffa500\"],[\"#6495ed\",\"#008000\",\"#f4a460\"],[\"#1e90ff\",\"#006400\",\"#ff8c00\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Отображение полученных графиков","metadata":{}},{"cell_type":"code","source":"fig2 = go.Figure()\n\nfig2 = make_subplots(rows=4, cols=1)\n\nx_hum2 = predictions[\"LSTM\"][\"humidity\"].index\ny_hum2 = predictions[\"LSTM\"][\"humidity\"][\"humidity1\"]\nx_hum_p2 = predictions[\"LSTM\"][\"humidity\"].index \ny_hum_p2 = predictions[\"LSTM\"][\"humidity\"][\"prediction\"]\nx_wind2 = predictions[\"LSTM\"][\"wind_speed\"].index \ny_wind2 = predictions[\"LSTM\"][\"wind_speed\"][\"wind_speed1\"]\nx_wind_p2 = predictions[\"LSTM\"][\"wind_speed\"].index\ny_wind_p2 = predictions[\"LSTM\"][\"wind_speed\"][\"prediction\"]\nx_pres2 = predictions[\"LSTM\"][\"meanpressure\"].index\ny_pres2 = predictions[\"LSTM\"][\"meanpressure\"][\"meanpressure1\"]\nx_pres_p2 = predictions[\"LSTM\"][\"meanpressure\"].index \ny_pres_p2 = predictions[\"LSTM\"][\"meanpressure\"][\"prediction\"]\nx_temp2 = predictions[\"LSTM\"][\"meantemp\"].index\ny_temp2 = predictions[\"LSTM\"][\"meantemp\"][\"meantemp1\"]\nx_temp_p2 = predictions[\"LSTM\"][\"meantemp\"].index\ny_temp_p2 = predictions[\"LSTM\"][\"meantemp\"][\"prediction\"]\n\nx_hum3 = predictions[\"ODENET\"][\"humidity\"].index\ny_hum3 = predictions[\"ODENET\"][\"humidity\"][\"humidity1\"]\nx_hum_p3 = predictions[\"ODENET\"][\"humidity\"].index \ny_hum_p3 = predictions[\"ODENET\"][\"humidity\"][\"prediction\"]\nx_wind3 = predictions[\"ODENET\"][\"wind_speed\"].index \ny_wind3 = predictions[\"ODENET\"][\"wind_speed\"][\"wind_speed1\"]\nx_wind_p3 = predictions[\"ODENET\"][\"wind_speed\"].index\ny_wind_p3 = predictions[\"ODENET\"][\"wind_speed\"][\"prediction\"]\nx_pres3 = predictions[\"ODENET\"][\"meanpressure\"].index\ny_pres3 = predictions[\"ODENET\"][\"meanpressure\"][\"meanpressure1\"]\nx_pres_p3 = predictions[\"ODENET\"][\"meanpressure\"].index \ny_pres_p3 = predictions[\"ODENET\"][\"meanpressure\"][\"prediction\"]\nx_temp3 = predictions[\"ODENET\"][\"meantemp\"].index\ny_temp3 = predictions[\"ODENET\"][\"meantemp\"][\"meantemp1\"]\nx_temp_p3 = predictions[\"ODENET\"][\"meantemp\"].index\ny_temp_p3 = predictions[\"ODENET\"][\"meantemp\"][\"prediction\"]\n\n#[\"humidity\", \"wind_speed\", \"meanpressure\", \"meantemp\"]\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#f20089\"),\n    x=x_hum2, y=y_hum2,\n    mode='lines',\n    name='Истинная влажность'), row = 1, col = 1)\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#e500a4\"),\n    x=x_wind2, y=y_wind2,\n    mode='lines',\n    name='Истинная скорость ветра'), row = 2, col = 1)\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#db00b6\"),\n    x=x_pres2, y=y_pres2,\n    mode='lines',\n    name='Истинное среднее давление'), row = 3, col = 1)\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#d100d1\"),\n    x=x_temp2, y=y_temp2,\n    mode='lines',\n    name='Истинная средняя температура'), row = 4, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#ffba08\"),\n    x=x_hum_p2, y=y_hum_p2,\n    mode='lines',\n    name='LSTM Предсказанная влажность'), row = 1, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#faa307\"),\n    x=x_wind_p2, y=y_wind_p2,\n    mode='lines',\n    name='LSTM Предсказанная скорость ветра'), row = 2, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#f48c06\"),\n    x=x_pres_p2, y=y_pres_p2,\n    mode='lines',\n    name='LSTM Предсказанное среднее давление'), row = 3, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#e85d04\"),\n    x=x_temp_p2, y=y_temp_p2,\n    mode='lines',\n    name='LSTM Предсказанная средняя температура'), row = 4, col = 1)\n\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#9ef01a\"),\n    x=x_hum_p3, y=y_hum_p3,\n    mode='lines',\n    name='ODENET Предсказанная влажность'), row = 1, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#70e000\"),\n    x=x_wind_p3, y=y_wind_p3,\n    mode='lines',\n    name='ODENET Предсказанная скорость ветра'), row = 2, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#38b000\"),\n    x=x_pres_p3, y=y_pres_p3,\n    mode='lines',\n    name='ODENET Предсказанное среднее давление'), row = 3, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#008000\"),\n    x=x_temp_p3, y=y_temp_p3,\n    mode='lines',\n    name='ODENET Предсказанная средняя температура'), row = 4, col = 1)\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#caf0f8\"),\n    x=hum_concated.index, y=hum_concated,\n    mode='lines',\n    name='SARIMA Предсказанная влажность'), row = 1, col = 1)\n\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#90e0ef\"),\n    x=wind_concated.index, y=wind_concated,\n    mode='lines',\n    name='SARIMA Предсказанная скорость ветра'), row = 2, col = 1)\n\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#00b4d8\"),\n    x=pres_concated.index, y=pres_concated,\n    mode='lines',\n    name='SARIMA Предсказанное среднее давление'), row = 3, col = 1)\n\n\nfig2.add_trace(go.Scatter(\n    line=dict(color=\"#0077b6\"),\n    x=temp_concated.index, y=temp_concated,\n    mode='lines',\n    name='SARIMA Предсказанная средняя температура'), row = 4, col = 1)\n\nfig2.update_xaxes(title_text='Время', row=1, col=1)\nfig2.update_yaxes(title_text='Влажность, %', row=1, col=1)\n\nfig2.update_xaxes(title_text='Время', row=2, col=1)\nfig2.update_yaxes(title_text='Скорость ветра, м/с', row=2, col=1)\n\nfig2.update_xaxes(title_text='Время', row=3, col=1)\nfig2.update_yaxes(title_text='Давление, мбар', row=3, col=1)\n\nfig2.update_xaxes(title_text='Время', row=4, col=1)\nfig2.update_yaxes(title_text='Температура, цельсий', row=4, col=1)\n\nfig2.update_layout(height=800)\n\n\nfig2.add_vline(x=test_start, line_width=2, line_dash=\"dash\")\nfig2.add_annotation(x=test_start, y=10, text=\"Начало теста\", showarrow=False)\n\nfig2.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Отображение различных данных о полученных моделях","metadata":{}},{"cell_type":"code","source":"#\"humidity\", \"wind_speed\", \"meanpressure\", \"meantemp\"\nprint(f\"MSE влажность SARIMA: \", mean_absolute_error(predictions[mdl[\"name\"]][\"humidity\"][\"humidity1\"][\"2016-01-01\":], sarimax_pred_hum))\nprint(f\"MSE скорость ветра SARIMA: \", mean_absolute_error(predictions[mdl[\"name\"]][\"wind_speed\"][\"wind_speed1\"][\"2016-01-01\":], sarimax_pred_wind))\nprint(f\"MSE среднее давление SARIMA: \", mean_absolute_error(predictions[mdl[\"name\"]][\"meanpressure\"][\"meanpressure1\"][\"2016-01-01\":], sarimax_pred_pres))\nprint(f\"MSE средняя температура SARIMA: \", mean_absolute_error(predictions[mdl[\"name\"]][\"meantemp\"][\"meantemp1\"][\"2016-01-01\":], sarimax_pred_temp))\nprint(\"SARIMA MEMORY\")\n\nprint(\"SARIMA влажность память\", asizeof.asizeof(sarimax_res_hum))\nprint(\"SARIMA ветер память\", asizeof.asizeof(sarimax_res_wind))\nprint(\"SARIMA давление память\", asizeof.asizeof(sarimax_res_pres))\nprint(\"SARIMA температура память\", asizeof.asizeof(sarimax_res_temp))\n\nfor mdl in models:\n    print(f\"MSE влажность {mdl['name']}: \", mean_absolute_error(predictions[mdl[\"name\"]][\"humidity\"][\"humidity1\"][\"2016-01-01\":], predictions[mdl[\"name\"]][\"humidity\"][\"prediction\"][\"2016-01-01\":]))\n    print(f\"MSE скорость ветра {mdl['name']}: \", mean_absolute_error(predictions[mdl[\"name\"]][\"wind_speed\"][\"wind_speed1\"][\"2016-01-01\":], predictions[mdl[\"name\"]][\"wind_speed\"][\"prediction\"][\"2016-01-01\":]))\n    print(f\"MSE среднее давление {mdl['name']}: \", mean_absolute_error(predictions[mdl[\"name\"]][\"meanpressure\"][\"meanpressure1\"][\"2016-01-01\":], predictions[mdl[\"name\"]][\"meanpressure\"][\"prediction\"][\"2016-01-01\":]))\n    print(f\"MSE средняя температура {mdl['name']}: \", mean_absolute_error(predictions[mdl[\"name\"]][\"meantemp\"][\"meantemp1\"][\"2016-01-01\":], predictions[mdl[\"name\"]][\"meantemp\"][\"prediction\"][\"2016-01-01\":]))\n    \n    print(f\"Время тренировки влажность {mdl['name']}: \", mdl[\"hwpt_train\"])\n    print(f\"Время тренировки скорость ветра {mdl['name']}: \", mdl[\"hwpt_train\"])\n    print(f\"Время тренировки среднее давление {mdl['name']}: \", mdl[\"hwpt_train\"])\n    print(f\"Время тренировки средняя температура {mdl['name']}: \", mdl[\"hwpt_train\"])\n    \n    print(f\"Время теста влажность {mdl['name']}: \", mdl[\"hwpt_test\"])\n    print(f\"Время теста скорость ветра {mdl['name']}: \", mdl[\"hwpt_test\"])\n    print(f\"Время теста среднее давление {mdl['name']}: \", mdl[\"hwpt_test\"])\n    print(f\"Время теста средняя температура {mdl['name']}: \", mdl[\"hwpt_test\"])\n    print(\"\\n\")\n    \nfor mdl in models:\n    print(str(mdl))\n    print(f\"Число параметров {mdl['params']}\")\n    print(f\"Используемая память {mdl['memory']}\")\n    print(f\"Используемая память asizeof {mdl['other_memory']}\")\n    print(\"\\n\")\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}